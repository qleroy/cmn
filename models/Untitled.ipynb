{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/Users/quentinleroy/mva/recvis/project/cmn/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from models import modules, fastrcnn_vgg_net, lstm_net\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import convert_to_tensor as to_T\n",
    "\n",
    "def visgeno_attbilstm_net(input_batch, bbox_batch, spatial_batch, expr_obj,\n",
    "    num_vocab, embed_dim, lstm_dim, vgg_dropout, lstm_dropout):\n",
    "    #   bbox_batch has shape [N_box, 5] and\n",
    "    #   spatial_batch has shape [N_box, D_spatial] and\n",
    "    #   expr_obj has shape [T, N_batch]\n",
    "\n",
    "    N_batch = tf.shape(expr_obj)[1]\n",
    "    N_box = tf.shape(spatial_batch)[0]\n",
    "\n",
    "    # Extract visual features\n",
    "    vis_feat = fastrcnn_vgg_net.vgg_roi_fc7(input_batch, bbox_batch,\n",
    "        \"vgg_local\", apply_dropout=vgg_dropout)\n",
    "    D_vis = vis_feat.get_shape().as_list()[-1]\n",
    "\n",
    "    # Extract representation using attention\n",
    "    lang_obj1, lang_obj2, lang_relation = lstm_net.attbilstm(\n",
    "        expr_obj, \"lstm\", num_vocab=num_vocab, embed_dim=embed_dim,\n",
    "        lstm_dim=lstm_dim, apply_dropout=lstm_dropout)\n",
    "\n",
    "    # Score for each bounding box matching the first object\n",
    "    # scores_obj1 has shape [N_batch, N_box, 1]\n",
    "    scores_obj1 = modules.localization_module_grid_score(vis_feat,\n",
    "        spatial_batch, lang_obj1)\n",
    "    # Score for each bounding box matching the second object\n",
    "    # scores_obj2 has shape [N_batch, N_box, 1]\n",
    "    scores_obj2 = modules.localization_module_grid_score(vis_feat,\n",
    "        spatial_batch, lang_obj2, reuse=True)\n",
    "\n",
    "    # Scores for each pair of bounding box matching the relationship\n",
    "    # Tile the scores by broadcasting add\n",
    "    # scores_rel has shape [N_batch, N_box, N_box, 1]\n",
    "    scores_rel = modules.relationship_module_spatial_only_grid_score(\n",
    "        spatial_batch, scores_obj1, spatial_batch, scores_obj2, lang_relation,\n",
    "        rescale_scores=True)\n",
    "    tf.add_to_collection(\"s_pair\", scores_rel)\n",
    "\n",
    "    return scores_rel\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
